{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing_Sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing with RNN"
      ],
      "metadata": {
        "id": "M4-PbAGcylPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting textual data to numerical data:\n",
        "-  Bag of words: represent each word by a number. Then we keep the track of the frequencies of each words. This method loses the order of the words in the original text. \n",
        "- Integer Encoding: mapping each word with an integer and save the order of words in each text. The issue is that the numbers which present the words are actually important but we do not control them.\n",
        "- Word Embeddings: represent every word into a vector, this vector has n dimension (64, 128). We hope that the similar words will have the same direction as vectors, the angle between these vectors are not big. Word Embeddings are trainable layer, we can use pretrained layer."
      ],
      "metadata": {
        "id": "JDfgEn6zzi0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bag of Words"
      ],
      "metadata": {
        "id": "Ga0khnd41sqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1f5gj0UtEZf",
        "outputId": "53b8d31e-4430-4a52-d4e8-9c60aca71e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ]
        }
      ],
      "source": [
        "vocab = {}  # maps word to integer representing it\n",
        "word_encoding = 1\n",
        "def bag_of_words(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
        "  bag = {}  # stores all of the encodings and their frequency\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      encoding = vocab[word]  # get encoding from vocab\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding = word_encoding\n",
        "      word_encoding += 1\n",
        "    \n",
        "    if encoding in bag:\n",
        "      bag[encoding] += 1\n",
        "    else:\n",
        "      bag[encoding] = 1\n",
        "  \n",
        "  return bag\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "bag = bag_of_words(text)\n",
        "print(bag)\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_bag)\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn6IP9f31ZrF",
        "outputId": "1b973043-6d67-4278-80d7-f36be38c99e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis\n",
        "We will use movie reviews dataset from Keras to analyze sentiment in them. The reviews are already processed and labeled."
      ],
      "metadata": {
        "id": "WE09AM6U3Kr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports and downloaging the dataset"
      ],
      "metadata": {
        "id": "EwIeBnEXSjD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584 # the number of unique words in the dataset\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "paa5Q7oj1cn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7784b314-55f3-4b56-f43c-aa2d810a52b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all the sequences should be with the same length => padding \n",
        "# padding is trimming the extra words or add some words to meet the necessary length\n",
        "btrain_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "metadata": {
        "id": "Ol-Jc9LqJ3h1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building, compiling and training the model"
      ],
      "metadata": {
        "id": "qY919YZRSnoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32), # the output vectors are with dimension 32 \n",
        "    tf.keras.layers.LSTM(32), \n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") # sigmoid sqesh the values between 0 and 1\n",
        "])"
      ],
      "metadata": {
        "id": "ByXcanJ5J4bE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQz5eUY2J5g8",
        "outputId": "46fa2488-f5f9-4a4d-c2a2-adbaaa8b2ec3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          2834688   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "# use 20% of the training data for validation\n",
        "history = model.fit(btrain_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_J4pbWYJ6YE",
        "outputId": "d35b08a7-6f49-4428-bf1e-a1c207b1d021"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 44s 59ms/step - loss: 0.4238 - acc: 0.8124 - val_loss: 0.3060 - val_acc: 0.8742\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.2374 - acc: 0.9114 - val_loss: 0.2808 - val_acc: 0.8882\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.1805 - acc: 0.9363 - val_loss: 0.3017 - val_acc: 0.8964\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.1520 - acc: 0.9460 - val_loss: 0.3255 - val_acc: 0.8938\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.1290 - acc: 0.9556 - val_loss: 0.3312 - val_acc: 0.8844\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.1106 - acc: 0.9627 - val_loss: 0.3053 - val_acc: 0.8922\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.0968 - acc: 0.9689 - val_loss: 0.6728 - val_acc: 0.8250\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.0860 - acc: 0.9724 - val_loss: 0.3276 - val_acc: 0.8848\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.0750 - acc: 0.9757 - val_loss: 0.3551 - val_acc: 0.8874\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.0659 - acc: 0.9780 - val_loss: 0.4170 - val_acc: 0.8612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating the model"
      ],
      "metadata": {
        "id": "XvsXxg3pSsZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2guRd3MuJ7dk",
        "outputId": "bee99891-9455-4957-f5b2-2bf9f8318874"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4618 - acc: 0.8445\n",
            "[0.4618006944656372, 0.8445199728012085]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting\n",
        "##### Making an encoding function"
      ],
      "metadata": {
        "id": "gpweiPbDSu29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction, we want to preprocess the data precisly the same way we have processed the trianing data\n",
        "word_index = imdb.get_word_index() # Get the word  indexing\n",
        "\n",
        "# encoding function\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text) # Tokenizing\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens] #replacing each word with its integer index\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0] # padding and returning, the padding return a list that's why we are returning the first element which is the padding of the sequence \n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rFLsoRwJ8Wk",
        "outputId": "aa9a32cb-4ee7-4bc1-c611-98cb062496bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value: key for (key, value) in word_index.items()} # reverse the lookup table\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0 # if we see 0, then there is no words there\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "  \n",
        "print(decode_integers(encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8yHPbOKJ9MW",
        "outputId": "adb81c73-3234-4420-ca9a-e47813ea744f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that movie was just amazing so amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Predicting"
      ],
      "metadata": {
        "id": "KiB6JsJ6Ul0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text) # Encoding the function\n",
        "  pred = np.zeros((1,250))         # Create a zeros array, the length of the revies is 250\n",
        "  pred[0] = encoded_text           # the model is optimized on passing a list of sequences\n",
        "  result = model.predict(pred) \n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayjWNlQtJ-JM",
        "outputId": "e7e76958-4d84-491a-f9f3-b7706dc2a89b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.86819285]\n",
            "[0.39357874]\n"
          ]
        }
      ]
    }
  ]
}